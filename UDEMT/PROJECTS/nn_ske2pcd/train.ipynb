{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch3d as p3d\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.io import load_obj, load_ply, save_ply\n",
    "from pytorch3d.loss import chamfer_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config\n",
    "\n",
    "# 定义点云数据的输入维度和输出维度\n",
    "input_dim = 3  # 每个点的特征维度\n",
    "output_dim = 3  # 输出点云的特征维度（可以与输入维度相同）\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_epochs = 300\n",
    "batch_size = 15\n",
    "\n",
    "sxxxxes = os.listdir(\"../../data/all_results/\")\n",
    "train_sxxxxes = sxxxxes[:372]\n",
    "test_sxxxxes = sxxxxes[372:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个简单的全连接神经网络类\n",
    "class PointCloudFCNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(PointCloudFCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)  # 输入层到隐藏层1\n",
    "        self.fc2 = nn.Linear(64, 128)  # 隐藏层1到隐藏层2\n",
    "        self.fc3 = nn.Linear(128, 256)  # 隐藏层2到隐藏层3\n",
    "        self.fc4 = nn.Linear(256, 128)  # 隐藏层3到隐藏层4\n",
    "        self.fc5 = nn.Linear(128, output_dim)  # 隐藏层4到输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)  # 输出层不使用激活函数\n",
    "        return x\n",
    "\n",
    "\n",
    "# DataSet类\n",
    "class TrainingSet(Dataset):\n",
    "    def __init__(self, s_name_list, transform=None, sample_num=5000) -> None:\n",
    "        self.input = [\n",
    "            f\"../../data/all_results/{sname}/0_sphere.obj\" for sname in s_name_list\n",
    "        ]\n",
    "        self.target = [\n",
    "            f\"../../data/all_results/{sname}/{sname}.ply\" for sname in s_name_list\n",
    "        ]\n",
    "        self.sample_num = sample_num\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #对input采样5000个点\n",
    "        input_tensor_points, input_tensor_faces, _ = load_obj(self.input[index], load_textures=False)\n",
    "        input_mesh = Meshes([input_tensor_points], [input_tensor_faces.verts_idx]) #注意这里有个.verts_idx\n",
    "        input_tensor_points_sampled = sample_points_from_meshes(input_mesh,5000).squeeze(0)\n",
    "        #对output采样5000个点\n",
    "        target_tensor_points, target_tensor_faces = load_ply(self.target[index])\n",
    "        target_mesh = Meshes([target_tensor_points],[target_tensor_faces])\n",
    "        target_tensor_points_sampled = sample_points_from_meshes(target_mesh).squeeze(0)\n",
    "\n",
    "        return input_tensor_points_sampled.to(device),target_tensor_points_sampled.to(device)\n",
    "\n",
    "    def get_target(self, input):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# pts,faces = load_ply(f\"../../data/all_results/s0004_pulmonary_artery.nii.g_1/s0004_pulmonary_artery.nii.g_1.ply\")\n",
    "# mymesh = Meshes([pts],[faces])\n",
    "# a = sample_points_from_meshes(mymesh,5)\n",
    "# a = a.squeeze(0)\n",
    "# a\n",
    "# mymesh\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pointcloud(points, title=\"\"):\n",
    "    \"\"\"Sample points uniformly from the surface of the mesh.\"\"\"\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.scatter3D(x, z, -y)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"z\")\n",
    "    ax.set_zlabel(\"y\")\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(190, 30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_dataset = TrainingSet(train_sxxxxes)\n",
    "data_loader = DataLoader(my_train_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloudFCNet(\n",
       "  (fc1): Linear(in_features=3, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc5): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建模型实例\n",
    "model = PointCloudFCNet(input_dim, output_dim).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = chamfer_distance\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 使用Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 1.1201e-03, -1.2780e-01, -1.5456e-01],\n",
       "          [ 3.3912e-01, -1.8870e-01, -2.6119e-01],\n",
       "          [ 2.2809e-01,  2.8302e-02,  1.3687e-01],\n",
       "          ...,\n",
       "          [ 3.8677e-01, -2.7883e-01, -2.1206e-01],\n",
       "          [-5.6391e-01, -3.5518e-01, -1.0207e-01],\n",
       "          [ 4.0928e-01,  1.0788e-02,  2.7254e-02]],\n",
       " \n",
       "         [[-1.5282e-01, -2.0984e-01,  1.6452e-01],\n",
       "          [-2.3907e-01,  3.5701e-01, -8.6453e-02],\n",
       "          [ 4.6404e-01, -2.3882e-01,  1.0162e-01],\n",
       "          ...,\n",
       "          [-2.1422e-01,  3.3570e-01, -4.4510e-02],\n",
       "          [-1.6109e-01,  3.1048e-01, -2.6347e-01],\n",
       "          [-1.4922e-01,  3.7911e-01, -4.1280e-01]],\n",
       " \n",
       "         [[ 7.1821e-01, -7.7784e-02,  2.4465e-04],\n",
       "          [ 5.5877e-01,  3.0769e-02, -7.9908e-02],\n",
       "          [-1.2117e-02, -2.1917e-01,  2.5476e-01],\n",
       "          ...,\n",
       "          [ 4.2557e-01, -3.5235e-02, -5.9317e-02],\n",
       "          [-5.8487e-02,  2.5119e-01,  1.5489e-01],\n",
       "          [ 1.1165e-01,  3.8742e-01,  3.9525e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 4.3305e-01, -7.9253e-02, -1.3992e-02],\n",
       "          [ 6.4337e-01, -3.1036e-01, -1.4776e-01],\n",
       "          [-2.1304e-01,  2.5526e-01, -1.7725e-01],\n",
       "          ...,\n",
       "          [-6.3769e-02,  5.2620e-01,  1.3129e-01],\n",
       "          [ 1.0718e-01, -1.6109e-01, -4.0443e-02],\n",
       "          [ 3.7521e-01, -2.8933e-01, -2.5071e-01]],\n",
       " \n",
       "         [[-1.7593e-01,  1.9486e-01, -2.0321e-01],\n",
       "          [-3.1675e-01, -2.1241e-01,  1.9103e-01],\n",
       "          [-3.8721e-01, -6.6687e-01,  1.9029e-01],\n",
       "          ...,\n",
       "          [ 3.2914e-01, -1.3754e-01, -1.0038e-01],\n",
       "          [ 5.8899e-01,  2.2947e-02, -3.3006e-01],\n",
       "          [-2.3014e-01,  5.2079e-01, -7.3303e-02]],\n",
       " \n",
       "         [[-1.2264e-01,  2.9778e-01,  3.4387e-02],\n",
       "          [-1.3401e-01,  4.1843e-01, -4.0245e-01],\n",
       "          [ 8.5054e-02,  2.6794e-01,  1.4703e-02],\n",
       "          ...,\n",
       "          [-4.0401e-01,  3.2830e-01, -3.3913e-01],\n",
       "          [ 3.7547e-01, -1.2615e-01,  1.1840e-01],\n",
       "          [ 4.6137e-01, -8.9741e-02, -3.6016e-02]]], device='cuda:0'),\n",
       " tensor([[[-0.3115, -0.0909,  0.0917],\n",
       "          [-0.1620, -0.2599,  0.0324],\n",
       "          [-0.2008,  0.6936,  0.1040],\n",
       "          ...,\n",
       "          [-0.6493, -0.5551, -0.3110],\n",
       "          [-0.4839, -0.4796,  0.1123],\n",
       "          [-0.1533, -0.1514,  0.0212]],\n",
       " \n",
       "         [[ 0.4000, -0.2997, -0.0544],\n",
       "          [-0.1210,  0.7753, -0.3804],\n",
       "          [-0.1663,  0.2595,  0.1157],\n",
       "          ...,\n",
       "          [-0.1434, -0.0027, -0.0068],\n",
       "          [-0.6559, -0.5388, -0.1047],\n",
       "          [ 0.6226, -0.3728,  0.0928]],\n",
       " \n",
       "         [[-0.2305,  0.1999,  0.0379],\n",
       "          [-0.1627, -0.0217,  0.2967],\n",
       "          [ 0.5992,  0.0186, -0.2126],\n",
       "          ...,\n",
       "          [ 0.0589,  0.5420,  0.0848],\n",
       "          [ 0.6694, -0.1297,  0.1491],\n",
       "          [ 0.1430,  0.1524, -0.1063]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.6473, -0.5269, -0.0605],\n",
       "          [-0.3336, -0.0246,  0.2165],\n",
       "          [ 0.6253, -0.2879, -0.3244],\n",
       "          ...,\n",
       "          [-0.3952, -0.2331,  0.3129],\n",
       "          [ 0.2083, -0.2740, -0.1632],\n",
       "          [-0.1177, -0.2502,  0.2906]],\n",
       " \n",
       "         [[-0.1761, -0.4516,  0.0348],\n",
       "          [ 0.1502,  0.0564, -0.1879],\n",
       "          [-0.0154, -0.4091,  0.1291],\n",
       "          ...,\n",
       "          [ 0.0213,  0.3935, -0.0718],\n",
       "          [ 0.4270, -0.1437, -0.3092],\n",
       "          [ 0.2033,  0.0151,  0.2233]],\n",
       " \n",
       "         [[ 0.4963, -0.1422, -0.0011],\n",
       "          [-0.1168, -0.2063,  0.4885],\n",
       "          [ 0.2180, -0.2898,  0.0820],\n",
       "          ...,\n",
       "          [ 0.2869, -0.2912, -0.1737],\n",
       "          [-0.1397, -0.4343,  0.2235],\n",
       "          [ 0.4461, -0.3336,  0.0040]]], device='cuda:0')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 0.0411\n",
      "Epoch [2/300], Loss: 0.0153\n",
      "Epoch [3/300], Loss: 0.0098\n",
      "Epoch [4/300], Loss: 0.0088\n",
      "Epoch [5/300], Loss: 0.0083\n",
      "Epoch [6/300], Loss: 0.0080\n",
      "Epoch [7/300], Loss: 0.0078\n",
      "Epoch [8/300], Loss: 0.0077\n",
      "Epoch [9/300], Loss: 0.0076\n",
      "Epoch [10/300], Loss: 0.0074\n",
      "Epoch [11/300], Loss: 0.0074\n",
      "Epoch [12/300], Loss: 0.0073\n",
      "Epoch [13/300], Loss: 0.0072\n",
      "Epoch [14/300], Loss: 0.0070\n",
      "Epoch [15/300], Loss: 0.0070\n",
      "Epoch [16/300], Loss: 0.0070\n",
      "Epoch [17/300], Loss: 0.0069\n",
      "Epoch [18/300], Loss: 0.0069\n",
      "Epoch [19/300], Loss: 0.0067\n",
      "Epoch [20/300], Loss: 0.0068\n",
      "Epoch [21/300], Loss: 0.0067\n",
      "Epoch [22/300], Loss: 0.0066\n",
      "Epoch [23/300], Loss: 0.0066\n",
      "Epoch [24/300], Loss: 0.0065\n",
      "Epoch [25/300], Loss: 0.0065\n",
      "Epoch [26/300], Loss: 0.0064\n",
      "Epoch [27/300], Loss: 0.0064\n",
      "Epoch [28/300], Loss: 0.0064\n",
      "Epoch [29/300], Loss: 0.0063\n",
      "Epoch [30/300], Loss: 0.0062\n",
      "Epoch [31/300], Loss: 0.0063\n",
      "Epoch [32/300], Loss: 0.0062\n",
      "Epoch [33/300], Loss: 0.0061\n",
      "Epoch [34/300], Loss: 0.0062\n",
      "Epoch [35/300], Loss: 0.0061\n",
      "Epoch [36/300], Loss: 0.0062\n",
      "Epoch [37/300], Loss: 0.0061\n",
      "Epoch [38/300], Loss: 0.0061\n",
      "Epoch [39/300], Loss: 0.0061\n",
      "Epoch [40/300], Loss: 0.0060\n",
      "Epoch [41/300], Loss: 0.0061\n",
      "Epoch [42/300], Loss: 0.0060\n",
      "Epoch [43/300], Loss: 0.0061\n",
      "Epoch [44/300], Loss: 0.0060\n",
      "Epoch [45/300], Loss: 0.0060\n",
      "Epoch [46/300], Loss: 0.0060\n",
      "Epoch [47/300], Loss: 0.0060\n",
      "Epoch [48/300], Loss: 0.0060\n",
      "Epoch [49/300], Loss: 0.0060\n",
      "Epoch [50/300], Loss: 0.0059\n",
      "Epoch [51/300], Loss: 0.0059\n",
      "Epoch [52/300], Loss: 0.0060\n",
      "Epoch [53/300], Loss: 0.0059\n",
      "Epoch [54/300], Loss: 0.0060\n",
      "Epoch [55/300], Loss: 0.0059\n",
      "Epoch [56/300], Loss: 0.0060\n",
      "Epoch [57/300], Loss: 0.0060\n",
      "Epoch [58/300], Loss: 0.0060\n",
      "Epoch [59/300], Loss: 0.0059\n",
      "Epoch [60/300], Loss: 0.0059\n",
      "Epoch [61/300], Loss: 0.0060\n",
      "Epoch [62/300], Loss: 0.0059\n",
      "Epoch [63/300], Loss: 0.0060\n",
      "Epoch [64/300], Loss: 0.0060\n",
      "Epoch [65/300], Loss: 0.0060\n",
      "Epoch [66/300], Loss: 0.0060\n",
      "Epoch [67/300], Loss: 0.0060\n",
      "Epoch [68/300], Loss: 0.0060\n",
      "Epoch [69/300], Loss: 0.0060\n",
      "Epoch [70/300], Loss: 0.0060\n",
      "Epoch [71/300], Loss: 0.0060\n",
      "Epoch [72/300], Loss: 0.0059\n",
      "Epoch [73/300], Loss: 0.0060\n",
      "Epoch [74/300], Loss: 0.0060\n",
      "Epoch [75/300], Loss: 0.0059\n",
      "Epoch [76/300], Loss: 0.0059\n",
      "Epoch [77/300], Loss: 0.0059\n",
      "Epoch [78/300], Loss: 0.0060\n",
      "Epoch [79/300], Loss: 0.0059\n",
      "Epoch [80/300], Loss: 0.0059\n",
      "Epoch [81/300], Loss: 0.0059\n",
      "Epoch [82/300], Loss: 0.0059\n",
      "Epoch [83/300], Loss: 0.0059\n",
      "Epoch [84/300], Loss: 0.0059\n",
      "Epoch [85/300], Loss: 0.0059\n",
      "Epoch [86/300], Loss: 0.0059\n",
      "Epoch [87/300], Loss: 0.0059\n",
      "Epoch [88/300], Loss: 0.0059\n",
      "Epoch [89/300], Loss: 0.0059\n",
      "Epoch [90/300], Loss: 0.0059\n",
      "Epoch [91/300], Loss: 0.0059\n",
      "Epoch [92/300], Loss: 0.0059\n",
      "Epoch [93/300], Loss: 0.0058\n",
      "Epoch [94/300], Loss: 0.0059\n",
      "Epoch [95/300], Loss: 0.0059\n",
      "Epoch [96/300], Loss: 0.0058\n",
      "Epoch [97/300], Loss: 0.0059\n",
      "Epoch [98/300], Loss: 0.0058\n",
      "Epoch [99/300], Loss: 0.0059\n",
      "Epoch [100/300], Loss: 0.0058\n",
      "Epoch [101/300], Loss: 0.0058\n",
      "Epoch [102/300], Loss: 0.0058\n",
      "Epoch [103/300], Loss: 0.0058\n",
      "Epoch [104/300], Loss: 0.0059\n",
      "Epoch [105/300], Loss: 0.0058\n",
      "Epoch [106/300], Loss: 0.0058\n",
      "Epoch [107/300], Loss: 0.0058\n",
      "Epoch [108/300], Loss: 0.0058\n",
      "Epoch [109/300], Loss: 0.0058\n",
      "Epoch [110/300], Loss: 0.0058\n",
      "Epoch [111/300], Loss: 0.0058\n",
      "Epoch [112/300], Loss: 0.0058\n",
      "Epoch [113/300], Loss: 0.0058\n",
      "Epoch [114/300], Loss: 0.0057\n",
      "Epoch [115/300], Loss: 0.0058\n",
      "Epoch [116/300], Loss: 0.0058\n",
      "Epoch [117/300], Loss: 0.0057\n",
      "Epoch [118/300], Loss: 0.0057\n",
      "Epoch [119/300], Loss: 0.0057\n",
      "Epoch [120/300], Loss: 0.0058\n",
      "Epoch [121/300], Loss: 0.0057\n",
      "Epoch [122/300], Loss: 0.0057\n",
      "Epoch [123/300], Loss: 0.0057\n",
      "Epoch [124/300], Loss: 0.0056\n",
      "Epoch [125/300], Loss: 0.0057\n",
      "Epoch [126/300], Loss: 0.0057\n",
      "Epoch [127/300], Loss: 0.0057\n",
      "Epoch [128/300], Loss: 0.0057\n",
      "Epoch [129/300], Loss: 0.0057\n",
      "Epoch [130/300], Loss: 0.0057\n",
      "Epoch [131/300], Loss: 0.0057\n",
      "Epoch [132/300], Loss: 0.0056\n",
      "Epoch [133/300], Loss: 0.0057\n",
      "Epoch [134/300], Loss: 0.0057\n",
      "Epoch [135/300], Loss: 0.0057\n",
      "Epoch [136/300], Loss: 0.0056\n",
      "Epoch [137/300], Loss: 0.0056\n",
      "Epoch [138/300], Loss: 0.0056\n",
      "Epoch [139/300], Loss: 0.0057\n",
      "Epoch [140/300], Loss: 0.0056\n",
      "Epoch [141/300], Loss: 0.0056\n",
      "Epoch [142/300], Loss: 0.0056\n",
      "Epoch [143/300], Loss: 0.0056\n",
      "Epoch [144/300], Loss: 0.0057\n",
      "Epoch [145/300], Loss: 0.0056\n",
      "Epoch [146/300], Loss: 0.0055\n",
      "Epoch [147/300], Loss: 0.0056\n",
      "Epoch [148/300], Loss: 0.0055\n",
      "Epoch [149/300], Loss: 0.0056\n",
      "Epoch [150/300], Loss: 0.0055\n",
      "Epoch [151/300], Loss: 0.0055\n",
      "Epoch [152/300], Loss: 0.0056\n",
      "Epoch [153/300], Loss: 0.0056\n",
      "Epoch [154/300], Loss: 0.0056\n",
      "Epoch [155/300], Loss: 0.0056\n",
      "Epoch [156/300], Loss: 0.0056\n",
      "Epoch [157/300], Loss: 0.0056\n",
      "Epoch [158/300], Loss: 0.0055\n",
      "Epoch [159/300], Loss: 0.0056\n",
      "Epoch [160/300], Loss: 0.0056\n",
      "Epoch [161/300], Loss: 0.0056\n",
      "Epoch [162/300], Loss: 0.0056\n",
      "Epoch [163/300], Loss: 0.0055\n",
      "Epoch [164/300], Loss: 0.0056\n",
      "Epoch [165/300], Loss: 0.0055\n",
      "Epoch [166/300], Loss: 0.0055\n",
      "Epoch [167/300], Loss: 0.0056\n",
      "Epoch [168/300], Loss: 0.0056\n",
      "Epoch [169/300], Loss: 0.0055\n",
      "Epoch [170/300], Loss: 0.0056\n",
      "Epoch [171/300], Loss: 0.0055\n",
      "Epoch [172/300], Loss: 0.0055\n",
      "Epoch [173/300], Loss: 0.0055\n",
      "Epoch [174/300], Loss: 0.0055\n",
      "Epoch [175/300], Loss: 0.0055\n",
      "Epoch [176/300], Loss: 0.0054\n",
      "Epoch [177/300], Loss: 0.0055\n",
      "Epoch [178/300], Loss: 0.0054\n",
      "Epoch [179/300], Loss: 0.0055\n",
      "Epoch [180/300], Loss: 0.0054\n",
      "Epoch [181/300], Loss: 0.0054\n",
      "Epoch [182/300], Loss: 0.0054\n",
      "Epoch [183/300], Loss: 0.0054\n",
      "Epoch [184/300], Loss: 0.0054\n",
      "Epoch [185/300], Loss: 0.0054\n",
      "Epoch [186/300], Loss: 0.0054\n",
      "Epoch [187/300], Loss: 0.0055\n",
      "Epoch [188/300], Loss: 0.0054\n",
      "Epoch [189/300], Loss: 0.0055\n",
      "Epoch [190/300], Loss: 0.0056\n",
      "Epoch [191/300], Loss: 0.0055\n",
      "Epoch [192/300], Loss: 0.0055\n",
      "Epoch [193/300], Loss: 0.0055\n",
      "Epoch [194/300], Loss: 0.0055\n",
      "Epoch [195/300], Loss: 0.0055\n",
      "Epoch [196/300], Loss: 0.0054\n",
      "Epoch [197/300], Loss: 0.0055\n",
      "Epoch [198/300], Loss: 0.0054\n",
      "Epoch [199/300], Loss: 0.0055\n",
      "Epoch [200/300], Loss: 0.0055\n",
      "Epoch [201/300], Loss: 0.0055\n",
      "Epoch [202/300], Loss: 0.0055\n",
      "Epoch [203/300], Loss: 0.0055\n",
      "Epoch [204/300], Loss: 0.0056\n",
      "Epoch [205/300], Loss: 0.0055\n",
      "Epoch [206/300], Loss: 0.0056\n",
      "Epoch [207/300], Loss: 0.0056\n",
      "Epoch [208/300], Loss: 0.0056\n",
      "Epoch [209/300], Loss: 0.0056\n",
      "Epoch [210/300], Loss: 0.0056\n",
      "Epoch [211/300], Loss: 0.0057\n",
      "Epoch [212/300], Loss: 0.0056\n",
      "Epoch [213/300], Loss: 0.0056\n",
      "Epoch [214/300], Loss: 0.0057\n",
      "Epoch [215/300], Loss: 0.0055\n",
      "Epoch [216/300], Loss: 0.0056\n",
      "Epoch [217/300], Loss: 0.0056\n",
      "Epoch [218/300], Loss: 0.0055\n",
      "Epoch [219/300], Loss: 0.0056\n",
      "Epoch [220/300], Loss: 0.0055\n",
      "Epoch [221/300], Loss: 0.0055\n",
      "Epoch [222/300], Loss: 0.0055\n",
      "Epoch [223/300], Loss: 0.0056\n",
      "Epoch [224/300], Loss: 0.0055\n",
      "Epoch [225/300], Loss: 0.0055\n",
      "Epoch [226/300], Loss: 0.0055\n",
      "Epoch [227/300], Loss: 0.0056\n",
      "Epoch [228/300], Loss: 0.0057\n",
      "Epoch [229/300], Loss: 0.0057\n",
      "Epoch [230/300], Loss: 0.0056\n",
      "Epoch [231/300], Loss: 0.0056\n",
      "Epoch [232/300], Loss: 0.0056\n",
      "Epoch [233/300], Loss: 0.0056\n",
      "Epoch [234/300], Loss: 0.0055\n",
      "Epoch [235/300], Loss: 0.0056\n",
      "Epoch [236/300], Loss: 0.0057\n",
      "Epoch [237/300], Loss: 0.0056\n",
      "Epoch [238/300], Loss: 0.0057\n",
      "Epoch [239/300], Loss: 0.0057\n",
      "Epoch [240/300], Loss: 0.0057\n",
      "Epoch [241/300], Loss: 0.0056\n",
      "Epoch [242/300], Loss: 0.0057\n",
      "Epoch [243/300], Loss: 0.0057\n",
      "Epoch [244/300], Loss: 0.0057\n",
      "Epoch [245/300], Loss: 0.0056\n",
      "Epoch [246/300], Loss: 0.0056\n",
      "Epoch [247/300], Loss: 0.0056\n",
      "Epoch [248/300], Loss: 0.0056\n",
      "Epoch [249/300], Loss: 0.0055\n",
      "Epoch [250/300], Loss: 0.0056\n",
      "Epoch [251/300], Loss: 0.0056\n",
      "Epoch [252/300], Loss: 0.0055\n",
      "Epoch [253/300], Loss: 0.0055\n",
      "Epoch [254/300], Loss: 0.0055\n",
      "Epoch [255/300], Loss: 0.0056\n",
      "Epoch [256/300], Loss: 0.0055\n",
      "Epoch [257/300], Loss: 0.0055\n",
      "Epoch [258/300], Loss: 0.0054\n",
      "Epoch [259/300], Loss: 0.0054\n",
      "Epoch [260/300], Loss: 0.0055\n",
      "Epoch [261/300], Loss: 0.0055\n",
      "Epoch [262/300], Loss: 0.0055\n",
      "Epoch [263/300], Loss: 0.0055\n",
      "Epoch [264/300], Loss: 0.0054\n",
      "Epoch [265/300], Loss: 0.0055\n",
      "Epoch [266/300], Loss: 0.0055\n",
      "Epoch [267/300], Loss: 0.0055\n",
      "Epoch [268/300], Loss: 0.0054\n",
      "Epoch [269/300], Loss: 0.0055\n",
      "Epoch [270/300], Loss: 0.0054\n",
      "Epoch [271/300], Loss: 0.0054\n",
      "Epoch [272/300], Loss: 0.0054\n",
      "Epoch [273/300], Loss: 0.0054\n",
      "Epoch [274/300], Loss: 0.0053\n",
      "Epoch [275/300], Loss: 0.0054\n",
      "Epoch [276/300], Loss: 0.0053\n",
      "Epoch [277/300], Loss: 0.0055\n",
      "Epoch [278/300], Loss: 0.0054\n",
      "Epoch [279/300], Loss: 0.0054\n",
      "Epoch [280/300], Loss: 0.0054\n",
      "Epoch [281/300], Loss: 0.0054\n",
      "Epoch [282/300], Loss: 0.0054\n",
      "Epoch [283/300], Loss: 0.0055\n",
      "Epoch [284/300], Loss: 0.0054\n",
      "Epoch [285/300], Loss: 0.0054\n",
      "Epoch [286/300], Loss: 0.0053\n",
      "Epoch [287/300], Loss: 0.0053\n",
      "Epoch [288/300], Loss: 0.0053\n",
      "Epoch [289/300], Loss: 0.0054\n",
      "Epoch [290/300], Loss: 0.0054\n",
      "Epoch [291/300], Loss: 0.0053\n",
      "Epoch [292/300], Loss: 0.0053\n",
      "Epoch [293/300], Loss: 0.0054\n",
      "Epoch [294/300], Loss: 0.0054\n",
      "Epoch [295/300], Loss: 0.0053\n",
      "Epoch [296/300], Loss: 0.0053\n",
      "Epoch [297/300], Loss: 0.0053\n",
      "Epoch [298/300], Loss: 0.0053\n",
      "Epoch [299/300], Loss: 0.0053\n",
      "Epoch [300/300], Loss: 0.0053\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for input_point_cloud,target_point_cloud in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output_point_cloud = model(input_point_cloud)  # 前向传播\n",
    "        loss,_ = criterion(output_point_cloud, target_point_cloud)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 优化模型参数\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    # if (epoch + 1) % 5 == 0:\n",
    "    #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        # plot_pointcloud(output_point_cloud)# 绘制点云"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0228,  0.0194, -0.1228],\n",
       "        [ 0.0322, -0.0287, -0.0990],\n",
       "        [ 0.0581, -0.0345, -0.1035],\n",
       "        ...,\n",
       "        [-0.3258,  0.6229, -0.0555],\n",
       "        [-0.3130,  0.5785, -0.0096],\n",
       "        [-0.2497,  0.6825, -0.0189]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用训练好的模型生成新的点云数据\n",
    "try_input_point_cloud,_,_ = load_obj(\"../../data/all_results/s1272_pulmonary_artery.nii.g_1/0_sphere.obj\", load_textures=False)\n",
    "new_point_cloud = model(try_input_point_cloud.to(device))\n",
    "new_point_cloud\n",
    "# 输出的new_point_cloud包含了经过神经网络处理后的新点云数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_ply' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yaodong/codings/UDEMT_project/UDEMT/PROJECTS/nn_ske2pcd/train.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/yaodong/codings/UDEMT_project/UDEMT/PROJECTS/nn_ske2pcd/train.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#看一眼新的输出长啥样\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/yaodong/codings/UDEMT_project/UDEMT/PROJECTS/nn_ske2pcd/train.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m save_ply(\u001b[39m\"\u001b[39m\u001b[39m./9-20-1920.ply\u001b[39m\u001b[39m\"\u001b[39m,new_point_cloud)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_ply' is not defined"
     ]
    }
   ],
   "source": [
    "#看一眼新的输出长啥样\n",
    "save_ply(\"./9-20-1920.ply\",new_point_cloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ske2pcd_pt201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
