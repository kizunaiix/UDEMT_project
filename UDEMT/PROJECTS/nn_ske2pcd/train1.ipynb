{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import pytorch3d as p3d\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.io import load_obj, load_ply, save_ply\n",
    "from pytorch3d.loss import chamfer_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config\n",
    "\n",
    "test_date = \"10-04-0754\"\n",
    "note_msg = \"\"\"\n",
    "这次的训练用的是3-64-256-512-256-3网络，加上了bn层，设置学习率变动为每30轮减半。\n",
    "这次训练中展示的loss已经是平均的loss  \n",
    "           \"\"\"\n",
    "# 定义点云数据的输入维度和输出维度\n",
    "input_dim = 3  # 每个点的特征维度\n",
    "output_dim = 3  # 输出点云的特征维度（可以与输入维度相同）\n",
    "\n",
    "sxxxxes = os.listdir(\"../../data/all_results/\")\n",
    "train_sxxxxes = sxxxxes[:372]\n",
    "test_sxxxxes = sxxxxes[372:]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_epochs = 200\n",
    "batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个简单的全连接神经网络类\n",
    "class PointCloudFCNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(PointCloudFCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)  # 输入层到隐藏层1\n",
    "        self.bn1 = nn.BatchNorm1d(64)  # 添加BN层\n",
    "        self.fc2 = nn.Linear(64, 256)  # 隐藏层1到隐藏层2\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 512)  # 隐藏层2到隐藏层3\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.fc4 = nn.Linear(512, 256)  # 隐藏层3到隐藏层4\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.fc5 = nn.Linear(256, output_dim)  # 隐藏层4到输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))  # 在全连接层后添加BN\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.fc5(x)  # 输出层不使用激活函数\n",
    "        return x\n",
    "\n",
    "\n",
    "# DataSet类\n",
    "class TrainingSet(Dataset):\n",
    "    def __init__(self, s_name_list, transform=None, sample_num=5000) -> None:\n",
    "        self.input = [\n",
    "            f\"../../data/all_results/{sname}/0_sphere.obj\" for sname in s_name_list\n",
    "        ]\n",
    "        self.target = [\n",
    "            f\"../../data/all_results/{sname}/{sname}.ply\" for sname in s_name_list\n",
    "        ]\n",
    "        self.sample_num = sample_num\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #对input采样5000个点\n",
    "        input_tensor_points, input_tensor_faces, _ = load_obj(self.input[index], load_textures=False)\n",
    "        input_mesh = Meshes([input_tensor_points], [input_tensor_faces.verts_idx]) #注意这里有个.verts_idx\n",
    "        input_tensor_points_sampled = sample_points_from_meshes(input_mesh,5000).squeeze(0)\n",
    "        #对output不使用采样\n",
    "        target_tensor_points, target_tensor_faces = load_ply(self.target[index])\n",
    "        target_mesh = Meshes([target_tensor_points],[target_tensor_faces])\n",
    "        target_tensor_points_sampled = sample_points_from_meshes(target_mesh).squeeze(0)\n",
    "\n",
    "        return input_tensor_points_sampled.to(device),target_tensor_points_sampled.to(device)\n",
    "\n",
    "    def get_target(self, input):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# pts,faces = load_ply(f\"../../data/all_results/s0004_pulmonary_artery.nii.g_1/s0004_pulmonary_artery.nii.g_1.ply\")\n",
    "# mymesh = Meshes([pts],[faces])\n",
    "# a = sample_points_from_meshes(mymesh,5)\n",
    "# a = a.squeeze(0)\n",
    "# a\n",
    "# mymesh\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pointcloud(points, title=\"\"):\n",
    "    \"\"\"Sample points uniformly from the surface of the mesh.\"\"\"\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.scatter3D(x, z, -y)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"z\")\n",
    "    ax.set_zlabel(\"y\")\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(190, 30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_dataset = TrainingSet(train_sxxxxes)\n",
    "my_test_dataset = TrainingSet(test_sxxxxes)\n",
    "train_data_loader = DataLoader(my_train_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloudFCNet(\n",
       "  (fc1): Linear(in_features=3, out_features=64, bias=True)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bn4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc5): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建模型实例\n",
    "model = PointCloudFCNet(input_dim, output_dim).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = chamfer_distance\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # 使用Adam优化器\n",
    "\n",
    "# 创建一个StepLR学习率调度器，每个epoch后将学习率乘以0.9（这只是示例，你可以根据需要自定义）\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开log文件准备写入训练结果\n",
    "logf = open(f\"./logs/{test_date}.txt\",\"w\")\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    sum_loss = 0.0\n",
    "    for input_point_cloud,target_point_cloud in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output_point_cloud = model(input_point_cloud.squeeze(0))  # 前向传播 ，把(1,5000,3)变成了(5000,3) ,否则bn层会报错\n",
    "        loss,_ = criterion(output_point_cloud.unsqueeze(0), target_point_cloud)  # 计算损失 ，重新把(5000,3)变回(1,5000,3)\n",
    "        sum_loss += loss.item()\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 优化模型参数\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print(f'[{time.asctime()}]   Epoch [{epoch+1}/{num_epochs}],current_lr ={current_lr}, Loss: {sum_loss/len(my_train_dataset):.6f}',file=logf)\n",
    "    logf.flush()\n",
    "\n",
    "    # if (epoch + 1) % 5 == 0:\n",
    "    #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        # plot_pointcloud(output_point_cloud)# 绘制点云\n",
    "\n",
    "\n",
    "logf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "\n",
    "torch.save(model,f\"./models/{test_date}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "\n",
    "model = torch.load(f\"./models/{test_date}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1145,  0.0044,  0.2180],\n",
       "        [ 0.5254, -0.1371,  0.1565],\n",
       "        [ 0.4680, -0.1040,  0.1493],\n",
       "        ...,\n",
       "        [ 0.0727,  0.0514, -0.0985],\n",
       "        [ 0.1013,  0.0431, -0.0980],\n",
       "        [-0.1123,  0.1447, -0.1163]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用训练好的模型生成新的点云数据\n",
    "try_input_point_cloud,_,_ = load_obj(\"../../data/all_results/s1272_pulmonary_artery.nii.g_1/0_sphere.obj\", load_textures=False)\n",
    "new_point_cloud = model(try_input_point_cloud.to(device))\n",
    "new_point_cloud\n",
    "# 输出的new_point_cloud包含了经过神经网络处理后的新点云数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算对new_point_cloud的loss\n",
    "torch.cuda.empty_cache()\n",
    "test_data_loader = DataLoader(my_test_dataset, batch_size=1, shuffle=False)\n",
    "sum_loss = 0.0\n",
    "for input_point_cloud_test,target_point_cloud_test in test_data_loader:\n",
    "    # save_ply(\"./outTTT.ply\",model(x))\n",
    "    # save_ply(\"./tarTTT.ply\",target_point_cloud_test)\n",
    "    # save_ply(\"./inTTT.ply\",x)\n",
    "    lossT,_ = criterion(model(input_point_cloud_test.squeeze(0)).unsqueeze(0), target_point_cloud_test)\n",
    "    sum_loss += lossT.item()\n",
    "\n",
    "with open(f\"./logs/{test_date}.txt\",\"a\") as f:\n",
    "    print(f\"\\n\\navg_loss on test_set: {sum_loss/len(my_test_dataset):.6f}\",file=f)\n",
    "    print(f\"\\n\\n{note_msg}\",file=f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#看一眼新的输出长啥样\n",
    "save_ply(f\"./plys/s1272_{test_date}.ply\",new_point_cloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ske2pcd_pt201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
